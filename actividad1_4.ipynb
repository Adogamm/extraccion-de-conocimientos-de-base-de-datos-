{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "actividad1_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7TL3cLftlu5RGBk1pIVqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adogamm/extraccion-de-conocimientos-de-base-de-datos-/blob/main/actividad1_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQmX43o0FgN5"
      },
      "source": [
        "### Extracción de conocimientos de bases de datos\n",
        "### Grupo: 91\n",
        "### Carrera: Ingenieria en desarrollo y gestión de software\n",
        "### Alumno: Adolfo León Barrón\n",
        "### Profesor: Salvador Hernández Mendoza\n",
        "\n",
        "<hr>\n",
        "\n",
        "#  Explore y analice datos con Python.\n",
        "##### La exploración y el análisis de datos son el núcleo de la ciencia de datos. Los científicos de datos requieren habilidades en lenguajes como Python para explorar, visualizar y manipular datos.\n",
        "\n",
        "<hr>\n",
        "\n",
        "# Introducción\n",
        "\n",
        "Como era de esperar, el papel de un científico de datos implica principalmente explorar y analizar datos. Los resultados de un análisis pueden formar la base de un informe o un modelo de aprendizaje automático, pero todo comienza con los datos, siendo Python el lenguaje de programación más popular para los científicos de datos.\n",
        "\n",
        "Después de décadas de desarrollo de código abierto, Python proporciona una amplia funcionalidad con potentes bibliotecas estadísticas y numéricas:\n",
        "\n",
        "\n",
        "\n",
        "*   NumPy y Pandas simplifican el análisis y la manipulación de datos\n",
        "*   Matplotlib proporciona visualizaciones de datos atractivas\n",
        "*   Scikit-learn ofrece un análisis de datos predictivo simple y efectivo\n",
        "*   TensorFlow y PyTorch ofrecen capacidades de aprendizaje automático y aprendizaje profundo\n",
        "\n",
        "Por lo general, un proyecto de análisis de datos está diseñado para establecer conocimientos sobre un escenario particular o para probar una hipótesis.\n",
        "\n",
        "Por ejemplo, supongamos que un profesor universitario recopila datos de sus estudiantes, incluido el número de conferencias a las que asistieron, las horas dedicadas al estudio y la calificación final obtenida en el examen de fin de trimestre. El profesor podría analizar los datos para determinar si existe una relación entre la cantidad de estudios que realiza un alumno y la nota final que obtiene. El profesor podría usar los datos para probar la hipótesis de que solo los estudiantes que estudian durante un número mínimo de horas pueden esperar obtener una calificación aprobatoria.\n",
        "\n",
        "<hr>\n",
        "\n",
        "#Prerrequisitos\n",
        "\n",
        "*   Conocimiento de mátematicas básicas.\n",
        "*   Alguna experiencia programando en Python.\n",
        "\n",
        "<hr>\n",
        "\n",
        "# Temario\n",
        "\n",
        "*   Introducción\n",
        "*   Explore datos con Numpy y Pandas.\n",
        "*   Ejercicio: explorar datos con Numpy y Pandas.\n",
        "*   Visualizar datos.\n",
        "*   Ejercicio: visualizar datos con Matplotlib.\n",
        "*   Examinar datos del mundo real.\n",
        "*   Ejercicio: examinar datos del mundo real.\n",
        "*   Verificación de conocimientos.\n",
        "*   Resumen\n",
        "\n",
        "<hr>\n",
        "\n",
        "# Objetivos de aprendizaje\n",
        "En este módulo, podrá:\n",
        "\n",
        "*    Tareas comunes de exploración y análisis de datos.\n",
        "*   Cómo usar paquetes de Python como NumPy, Pandas y Matplotlib para analizar datos.\n",
        "\n",
        "# Explore datos con NumPy y Pandas\n",
        "Los científicos de datos pueden utilizar diversas herramientas y técnicas para explorar, visualizar y manipular datos. Una de las formas más comunes en las que los científicos de datos trabajan con datos es utilizar el lenguaje Python y algunos paquetes específicos para el procesamiento de datos.\n",
        "\n",
        "#¿Qué es NumPy?\n",
        "\n",
        "NumPy es una biblioteca de Python que brinda una funcionalidad comparable a las herramientas matemáticas como MATLAB y R. Si bien NumPy simplifica significativamente la experiencia del usuario, también ofrece funciones matemáticas integrales.\n",
        "\n",
        "#¿Qué es Pandas?\n",
        "\n",
        "Pandas es una biblioteca de Python extremadamente popular para el análisis y la manipulación de datos. Pandas es como Excel para Python: proporciona una funcionalidad fácil de usar para tablas de datos.\n",
        "\n",
        "![2-pandas-df.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQSiLfAqJj82"
      },
      "source": [
        "# Explore datos con un cuaderno Jupyter\n",
        "\n",
        "Los cuadernos de Jupyter son una forma popular de ejecutar scripts básicos con su navegador web. Por lo general, estos cuadernos son una sola página web, dividida en secciones de texto y secciones de código que se ejecutan en el servidor en lugar de en su máquina local. Esto significa que puede comenzar rápidamente sin necesidad de instalar Python u otras herramientas.\n",
        "\n",
        "#Prueba de hipotesis\n",
        "\n",
        "La exploración y el análisis de datos suele ser un proceso iterativo , en el que el científico de datos toma una muestra de datos y realiza los siguientes tipos de tareas para analizarlos y probar hipótesis:\n",
        "\n",
        "*    **Limpiar datos** para manejar errores, valores perdidos y otros problemas.\n",
        "*    **Aplicar técnicas estadísticas para comprender mejor los datos** y cómo se puede esperar que la muestra represente la población de datos del mundo real, lo que permite una variación aleatoria.\n",
        "*    **Visualice los datos ** para determinar las relaciones entre las variables y, en el caso de un proyecto de aprendizaje automático, identifique las características que son potencialmente predictivas de la etiqueta .\n",
        "*    Revise la hipótesis y repita el proceso.\n",
        "<br><br>\n",
        "\n",
        "<hr>\n",
        "\n",
        "# Ejercicio: explorar datos con NumPy y Pandas\n",
        "\n",
        "## Explorando datos con Python\n",
        "\n",
        "Una parte importante del rol de un científico de datos es explorar, analizar y visualizar datos. Existe una amplia gama de herramientas y lenguajes de programación que pueden usar para hacer esto; y uno de los enfoques más populares es usar cuadernos de Jupyter (como este) y Python.\n",
        "\n",
        "Python es un lenguaje de programación flexible que se utiliza en una amplia gama de escenarios; desde aplicaciones web hasta programación de dispositivos. Es extremadamente popular en la comunidad de ciencia de datos y aprendizaje automático debido a los muchos paquetes que admite para el análisis y la visualización de datos.\n",
        "\n",
        "En este cuaderno, exploraremos algunos de estos paquetes y aplicaremos técnicas básicas para analizar datos. No se pretende que sea un ejercicio completo de programación de Python; o incluso una inmersión profunda en el análisis de datos. Más bien, está pensado como un curso acelerado sobre algunas de las formas comunes en las que los científicos de datos pueden usar Python para trabajar con datos.\n",
        "\n",
        "**Nota:** Si nunca antes ha utilizado el entorno de Jupyter Notebooks, hay algunas cosas que debe tener en cuenta:\n",
        "\n",
        "*    Los cuadernos están formados por células . Algunas celdas (como esta) contienen texto de rebajas , mientras que otras (como la que está debajo de esta) contienen código.\n",
        "*    Puede ejecutar cada celda de código utilizando el botón ► **Ejecutar**. el botón ► **Ejecutar** aparecerá cuando pase el cursor sobre la celda.\n",
        "*    La salida de cada celda de código se mostrará inmediatamente debajo de la celda.\n",
        "*    Aunque las celdas de código se pueden ejecutar individualmente, algunas variables utilizadas en el código son globales para el portátil. Eso significa que debe ejecutar todas las celdas de códigoen orden . Puede haber dependencias entre las celdas de código, por lo que si omite una celda, es posible que las celdas siguientes no se ejecuten correctamente.\n",
        "\n",
        "## Explorando matrices de datos con NumPy\n",
        "\n",
        "Comencemos mirando algunos datos simples.\n",
        "\n",
        "Suponga que una universidad toma una muestra de las calificaciones de los estudiantes para una clase de ciencia de datos.\n",
        "\n",
        "Ejecute el código en la celda de abajo haciendo clic en el botón ► Ejecutar para ver los datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkOtQa1LViP"
      },
      "source": [
        "data = [50,50,47,97,49,3,53,42,26,74,82,62,37,15,70,27,36,35,48,52,63,64]\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3aa4JkFLcUo"
      },
      "source": [
        "\n",
        "\n",
        "Los datos se han cargado en una estructura de **lista** de Python, que es un buen tipo de datos para la manipulación de datos en general, pero no está optimizado para el análisis numérico. Para ello, vamos a utilizar el **NumPy** paquete, que incluye los tipos de datos y funciones específicas para trabajar con numeros en Python.\n",
        "\n",
        "Ejecute la celda a continuación para cargar los datos en una **matriz** NumPy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8wIpbeBOsT4"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "grades = np.array(data)\n",
        "print(grades)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B9NjKHgOt6A"
      },
      "source": [
        "En caso de que se esté preguntando acerca de las diferencias entre una lista y una matriz NumPy , comparemos cómo se comportan estos tipos de datos cuando los usamos en una expresión que los multiplica por 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ0VZ0MGO1o9"
      },
      "source": [
        "print (type(data),'x 2:', data * 2)\n",
        "print('---')\n",
        "print (type(grades),'x 2:', grades * 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "225pyR0aO4Lg"
      },
      "source": [
        "Tenga en cuenta que multiplicar una lista por 2 crea una nueva lista de dos veces la longitud con la secuencia original de elementos de la lista repetida. Al multiplicar una matriz NumPy, por otro lado, se realiza un cálculo por elementos en el que la matriz se comporta como un vector , por lo que terminamos con una matriz del mismo tamaño en la que cada elemento se ha multiplicado por 2.\n",
        "\n",
        "La conclusión clave de esto es que las matrices NumPy están diseñadas específicamente para admitir operaciones matemáticas en datos numéricos, lo que las hace más útiles para el análisis de datos que una lista genérica.\n",
        "\n",
        "Es posible que haya notado que el tipo de clase para la matriz numpy anterior es un numpy.ndarray . La nd indica que esta es una estructura que puede constar de múltiples dimensiones (puede tener n dimensiones). Nuestra instancia específica tiene una sola dimensión de calificaciones de los estudiantes.\n",
        "\n",
        "Ejecute la celda de abajo para ver la forma de la matriz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-3yL215O-jE"
      },
      "source": [
        "grades.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GpJNd8pPAEE"
      },
      "source": [
        "La forma confirma que esta matriz tiene una sola dimensión, que contiene 22 elementos (hay 22 grados en la lista original). Puede acceder a los elementos individuales de la matriz por su posición ordinal basada en cero. Consigamos el primer elemento (el que está en la posición 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Q2lEcDPCYY"
      },
      "source": [
        "grades[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19uxf6uZPEfc"
      },
      "source": [
        "\n",
        "\n",
        "Muy bien, ahora que conoce el camino alrededor de una matriz NumPy, es hora de realizar un análisis de los datos de calificaciones.\n",
        "\n",
        "Puede aplicar agregaciones entre los elementos de la matriz, así que busquemos la calificación promedio simple (en otras palabras, el valor medio de la calificación).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RefHHQM5PHS9"
      },
      "source": [
        "grades.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa-4AZzzPJEq"
      },
      "source": [
        "\n",
        "\n",
        "Entonces, la nota media es de alrededor de 50, más o menos en el medio del rango posible de 0 a 100.\n",
        "\n",
        "Agreguemos un segundo conjunto de datos para los mismos estudiantes, esta vez registrando el número típico de horas por semana que dedicaron a estudiar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8gJJCG8PLdO"
      },
      "source": [
        "#Definicion de matriz de horas estudiadas\n",
        "study_hours = [10.0,11.5,9.0,16.0,9.25,1.0,11.5,9.0,8.5,14.5,15.5,\n",
        "               13.75,9.0,8.0,15.5,8.0,9.0,6.0,10.0,12.0,12.5,12.0]\n",
        "\n",
        "# Creación de una matris NumPy de dos dimensiones (matriz de una matriz)\n",
        "student_data = np.array([study_hours, grades])\n",
        "\n",
        "# Mostrar el arreglo\n",
        "student_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5H5y32zPcYN"
      },
      "source": [
        "Ahora los datos consisten en una matriz bidimensional, una matriz de matrices. Veamos su forma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAsEWpERPgZo"
      },
      "source": [
        "# Mostrar la forma del arreglo 2D\n",
        "student_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd_ErDEgPomj"
      },
      "source": [
        "\n",
        "\n",
        "La matriz student_data contiene dos elementos, cada uno de los cuales es una matriz que contiene 22 elementos.\n",
        "\n",
        "Para navegar por esta estructura, debe especificar la posición de cada elemento en la jerarquía. Entonces, para encontrar el primer valor en la primera matriz (que contiene los datos de las horas de estudio), puede usar el siguiente código.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9JNgpFEPpID"
      },
      "source": [
        "# Mostrar el primer elemento del primer elemento\n",
        "student_data[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLNt4tBuPtvE"
      },
      "source": [
        "Ahora tiene una matriz multidimensional que contiene tanto el tiempo de estudio del estudiante como la información de calificaciones, que puede usar para comparar datos. Por ejemplo, ¿cómo se compara el tiempo medio de estudio con la nota media?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_vjZPRMPwHn"
      },
      "source": [
        "# Obtener el valor de la media de cada submatriz\n",
        "avg_study = student_data[0].mean()\n",
        "avg_grade = student_data[1].mean()\n",
        "\n",
        "print('Average study hours: {:.2f}\\nAverage grade: {:.2f}'.format(avg_study, avg_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHiYMrk4P6lV"
      },
      "source": [
        " # Explorando datos tabulares con Pandas\n",
        "\n",
        "Si bien NumPy proporciona muchas de las funciones que necesita para trabajar con números, y específicamente matrices de valores numéricos; Cuando comienza a trabajar con tablas de datos bidimensionales, el paquete Pandas ofrece una estructura más conveniente para trabajar: el DataFrame.\n",
        "\n",
        "Ejecute la siguiente celda para importar la biblioteca Pandas y cree un DataFrame con tres columnas. La primera columna es una lista de los nombres de los estudiantes, y la segunda y tercera columnas son las matrices NumPy que contienen el tiempo de estudio y los datos de las calificaciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmAn6xZ6QDhL"
      },
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_students = pd.DataFrame({'Name': ['Dan', 'Joann', 'Pedro', 'Rosie', 'Ethan', 'Vicky', 'Frederic', 'Jimmie', \n",
        "                                     'Rhonda', 'Giovanni', 'Francesca', 'Rajab', 'Naiyana', 'Kian', 'Jenny',\n",
        "                                     'Jakeem','Helena','Ismat','Anila','Skye','Daniel','Aisha'],\n",
        "                            'StudyHours':student_data[0],\n",
        "                            'Grade':student_data[1]})\n",
        "\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTuG3HCsQFJO"
      },
      "source": [
        "Tenga en cuenta que, además de las columnas que especificó, el DataFrame incluye un índice para identificar de forma única cada fila. Podríamos haber especificado el índice explícitamente y asignado cualquier tipo de valor apropiado (por ejemplo, una dirección de correo electrónico); pero como no especificamos un índice, se ha creado uno con un valor entero único para cada fila."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO4SXnj9QIhD"
      },
      "source": [
        "#  Encontrar y filtrar datos en un DataFrame\n",
        "\n",
        "Puede usar el método loc de DataFrame para recuperar datos para un valor de índice específico, como este."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcSG4mYjQHDz"
      },
      "source": [
        "# Obtener la informacion del index con valor 5\n",
        "df_students.loc[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2WMFVkEQa9B"
      },
      "source": [
        "También puede obtener los datos en un rango de valores de índice, como este:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLKcjCI1QbeR"
      },
      "source": [
        "# Obtener las filas con los valores de indice del 0 al 5\n",
        "df_students.loc[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXPYRzp2Qiv4"
      },
      "source": [
        "Además de poder usar el método loc para buscar filas según el índice, puede usar el método iloc para buscar filas según su posición ordinal en el DataFrame (independientemente del índice):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhQKOxr1Qm7l"
      },
      "source": [
        "# Obtener la informacion en las primeras 5 filas\n",
        "df_students.iloc[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W6koTYzQwmb"
      },
      "source": [
        "\n",
        "\n",
        "Mire cuidadosamente los iloc[0:5]resultados y compárelos con los loc[0:5]resultados que obtuvo anteriormente. ¿Puedes ver la diferencia?\n",
        "\n",
        "El método loc devolvió filas con etiqueta de índice en la lista de valores de 0 a 5 , que incluye 0 , 1 , 2 , 3 , 4 y 5 (seis filas). Sin embargo, el método iloc devuelve las filas en las posiciones incluidas en el rango de 0 a 5, y dado que los rangos de números enteros no incluyen el valor del límite superior, esto incluye las posiciones 0 , 1 , 2 , 3 y 4 (cinco filas) .\n",
        "\n",
        "iloc identifica valores de datos en un DataFrame por posición , que se extiende más allá de las filas a las columnas. Entonces, por ejemplo, puede usarlo para encontrar los valores de las columnas en las posiciones 1 y 2 en la fila 0, así:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMOSS1YqQxb9"
      },
      "source": [
        "df_students.iloc[0,[1,2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6XyAqaQzYJ"
      },
      "source": [
        "Volvamos al método loc y veamos cómo funciona con columnas. Recuerde que loc se usa para ubicar elementos de datos basados en valores de índice en lugar de posiciones. En ausencia de una columna de índice explícita, las filas en nuestro marco de datos se indexan como valores enteros, pero las columnas se identifican por su nombre:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utbray9QQ2p8"
      },
      "source": [
        "df_students.loc[0,'Grade']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGBO4tJ2Q32_"
      },
      "source": [
        "\n",
        "\n",
        "Aquí hay otro truco útil. Puede usar el método loc para buscar filas indexadas en función de una expresión de filtrado que haga referencia a columnas con nombre distintas del índice, como esta:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1KkxujoQ54W"
      },
      "source": [
        "df_students.loc[df_students['Name']=='Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QACBGZQNQ8O9"
      },
      "source": [
        "\n",
        "\n",
        "En realidad, no necesita usar explícitamente el método loc para hacer esto; simplemente puede aplicar una expresión de filtrado de DataFrame, como esta:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ5WrPJmQ9qI"
      },
      "source": [
        "df_students[df_students['Name']=='Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_GHHFkZQ_G3"
      },
      "source": [
        "\n",
        "\n",
        "Y en buena medida, puede lograr los mismos resultados utilizando el método de consulta de DataFrame , como este:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c50B33g6RBas"
      },
      "source": [
        "df_students.query('Name==\"Aisha\"')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aznu0M0wRDB9"
      },
      "source": [
        "\n",
        "\n",
        "Los tres ejemplos anteriores subrayan una verdad ocasionalmente confusa sobre trabajar con Pandas. A menudo, hay varias formas de lograr los mismos resultados. Otro ejemplo de esto es la forma en que se refiere al nombre de una columna de DataFrame. Puede especificar el nombre de la columna como un valor de índice con nombre (como en los df_students['Name']ejemplos que hemos visto hasta ahora), o puede usar la columna como una propiedad del DataFrame, así:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvZ0CvdzREvm"
      },
      "source": [
        "df_students[df_students.Name == 'Aisha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq-Hi4p6RHaY"
      },
      "source": [
        " # Cargando un DataFrame desde un archivo\n",
        " Construimos el DataFrame a partir de algunas matrices existentes. Sin embargo, en muchos escenarios del mundo real, los datos se cargan desde fuentes como archivos. Reemplacemos el DataFrame de calificaciones de los estudiantes con el contenido de un archivo de texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwUh8--GRPiX"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/grades.csv\n",
        "df_students = pd.read_csv('grades.csv',delimiter=',',header='infer')\n",
        "df_students.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP1eIwyoRRPx"
      },
      "source": [
        "El método read_csv de DataFrame se usa para cargar datos desde archivos de texto. Como puede ver en el código de ejemplo, puede especificar opciones como el delimitador de columna y qué fila (si hay alguna) contiene encabezados de columna (en este caso, el delimitador es una coma y la primera fila contiene los nombres de columna; estos son los configuración predeterminada, por lo que los parámetros podrían haberse omitido).\n",
        "\n",
        "#Manejo de valores perdidos\n",
        "\n",
        "Uno de los problemas más comunes con los que deben lidiar los científicos de datos es la falta de datos o los datos incompletos. Entonces, ¿cómo sabríamos que el DataFrame contiene valores faltantes? Puede usar el método **isnull** para identificar qué valores individuales son nulos, como este:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa0A3sTARdCa"
      },
      "source": [
        "df_students.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQrqYyRKRefl"
      },
      "source": [
        "\n",
        "\n",
        "Por supuesto, con un DataFrame más grande, sería ineficiente revisar todas las filas y columnas individualmente; para que podamos obtener la suma de los valores perdidos para cada columna, así:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klIFseVGRgs_"
      },
      "source": [
        "df_students.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZrhc9h5RhEv"
      },
      "source": [
        "Ahora sabemos que falta un valor de **StudyHours** y dos valores de **Grade** que faltan.\n",
        "\n",
        "Para verlos en contexto, podemos filtrar el marco de datos para incluir solo filas donde cualquiera de las columnas (eje 1 del marco de datos) sea nula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33FLbiSERpQK"
      },
      "source": [
        "df_students[df_students.isnull().any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VTMKSs1RqDd"
      },
      "source": [
        "Cuando se recupera el DataFrame, los valores numéricos faltantes se muestran como NaN ( no como un número ).\n",
        "\n",
        "Entonces, ahora que hemos encontrado los valores nulos, ¿qué podemos hacer con ellos?\n",
        "\n",
        "Un enfoque común es imputar valores de reemplazo. Por ejemplo, si falta el número de horas de estudio, podríamos simplemente asumir que el estudiante estudió durante un tiempo promedio y reemplazar el valor faltante con la media de horas de estudio. Para hacer esto, podemos usar el método fillna , así:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJJKuMSNRvRU"
      },
      "source": [
        "df_students.StudyHours = df_students.StudyHours.fillna(df_students.StudyHours.mean())\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_bGidTPRyUo"
      },
      "source": [
        "\n",
        "\n",
        "Alternativamente, puede ser importante asegurarse de que solo use datos que sepa que son absolutamente correctos; para que pueda eliminar filas o columnas que contienen valores nulos mediante el método dropna . En este caso, eliminaremos filas (eje 0 del DataFrame) donde alguna de las columnas contiene valores nulos.\n",
        "\n",
        "# Explore datos en el DataFrame\n",
        "\n",
        "Ahora que hemos limpiado los valores faltantes, estamos listos para explorar los datos en el DataFrame. Comencemos comparando la media de horas de estudio y calificaciones.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91nLiyQ-R72R"
      },
      "source": [
        "# Obtener la media de horas estudiadas usando la columna llamada index\n",
        "mean_study = df_students['StudyHours'].mean()\n",
        "\n",
        "# Obtener la media de calificacion usando la columna llamada propiedad\n",
        "mean_grade = df_students.Grade.mean()\n",
        "\n",
        "# Imprimir la media de horas estudiadas y la calificación\n",
        "print('Average weekly study hours: {:.2f}\\nAverage grade: {:.2f}'.format(mean_study, mean_grade))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1uqmHzfSVMC"
      },
      "source": [
        "\n",
        "\n",
        "De acuerdo, filtremos el DataFrame para encontrar solo los estudiantes que estudiaron por más de la cantidad de tiempo promedio.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-IffQLASVg4"
      },
      "source": [
        "# Obtener a los estudiantes que estudiaron hasta o mas allá de la media\n",
        "df_students[df_students.StudyHours > mean_study]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ed8h4-RSdYU"
      },
      "source": [
        "\n",
        "\n",
        "Tenga en cuenta que el resultado filtrado es en sí mismo un DataFrame, por lo que puede trabajar con sus columnas como cualquier otro DataFrame.\n",
        "\n",
        "Por ejemplo, busquemos la calificación promedio de los estudiantes que realizaron más tiempo de estudio que el promedio.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtXIjkjQSg2G"
      },
      "source": [
        "# ¿Cuál fue su nota media?\n",
        "df_students[df_students.StudyHours > mean_study].Grade.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OehkRvhSlJk"
      },
      "source": [
        "\n",
        "\n",
        "Supongamos que la calificación aprobatoria del curso es 60.\n",
        "\n",
        "Podemos usar esa información para agregar una nueva columna al DataFrame, indicando si cada estudiante aprobó o no.\n",
        "\n",
        "Primero, crearemos una **serie** Pandas que contiene el indicador de pasa / falla (Verdadero o Falso), y luego concatenamos esa serie como una nueva columna (eje 1) en el DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TaCEz0ySo8J"
      },
      "source": [
        "passes  = pd.Series(df_students['Grade'] >= 60)\n",
        "df_students = pd.concat([df_students, passes.rename(\"Pass\")], axis=1)\n",
        "\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muQfT9slSqqj"
      },
      "source": [
        "\n",
        "\n",
        "Los DataFrames están diseñados para datos tabulares y puede utilizarlos para realizar muchos de los tipos de operaciones de análisis de datos que puede realizar en una base de datos relacional; como agrupar y agregar tablas de datos.\n",
        "\n",
        "Por ejemplo, puede usar el método **groupby** para agrupar los datos de los estudiantes en grupos según la columna de **Aprobado** que agregó anteriormente y contar el número de nombres en cada grupo; en otras palabras, puede determinar cuántos estudiantes aprobaron y reprobaron.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hpKDf9mSvxO"
      },
      "source": [
        "print(df_students.groupby(df_students.Pass).Name.count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5hEq6hFSyqG"
      },
      "source": [
        "\n",
        "\n",
        "Puede agregar varios campos en un grupo utilizando cualquier función de agregación disponible. Por ejemplo, puede encontrar el tiempo medio de estudio y la calificación de los grupos de estudiantes que aprobaron y reprobaron el curso.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38cA9dglSy-8"
      },
      "source": [
        "print(df_students.groupby(df_students.Pass)['StudyHours', 'Grade'].mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C9wEW0oS383"
      },
      "source": [
        "\n",
        "\n",
        "Los DataFrames son increíblemente versátiles y facilitan la manipulación de datos. Muchas operaciones de DataFrame devuelven una nueva copia del DataFrame; por lo que si desea modificar un DataFrame pero mantener la variable existente, debe asignar el resultado de la operación a la variable existente. Por ejemplo, el siguiente código ordena los datos de los estudiantes en orden descendente de Grado y asigna el DataFrame ordenado resultante a la variable **df_students** original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQpjULRVS6HC"
      },
      "source": [
        "# Crear un DataFrame con la información ordenada por la calificación (Descendente)\n",
        "df_students = df_students.sort_values('Grade', ascending=False)\n",
        "\n",
        "# Mostrar el DataFrame\n",
        "df_students"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVqNyrj4TIXs"
      },
      "source": [
        "# Resumen\n",
        "\n",
        "¡Eso es todo por ahora!\n",
        "\n",
        "Numpy y DataFrames son los caballos de batalla de la ciencia de datos en Python. Nos proporcionan formas de cargar, explorar y analizar datos tabulares. Como veremos en los módulos siguientes, incluso los métodos de análisis avanzados suelen depender de Numpy y Pandas para estos importantes roles.\n",
        "\n",
        "En nuestro próximo libro de trabajo, veremos cómo crear gráficos y explorar sus datos de formas más interesantes."
      ]
    }
  ]
}